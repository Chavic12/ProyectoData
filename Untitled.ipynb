{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8bc57af-bc39-44f7-9bcb-ac8f746567e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.utpl.edu.ec/carreras/empresas\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "Datos guardados en el archivo CSV: datos_universidades.csv\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def parse_carrera_links(url):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Obtener enlaces de las carreras\n",
    "        div_grado_elements = soup.find_all('div', class_='grado')\n",
    "        carrera_links = [a['href'] for div in div_grado_elements for a in div.find_all('a')]\n",
    "        \n",
    "        return carrera_links\n",
    "    else:\n",
    "        print(\"No se pudo acceder a la página web.\")\n",
    "        return []\n",
    "\n",
    "def scrape_and_save_data(url):\n",
    "    # Realiza una solicitud HTTP para obtener el contenido HTML\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        html = response.content\n",
    "    else:\n",
    "        print(\"No se pudo acceder a la página web.\")\n",
    "        return\n",
    "    \n",
    "    # Continúa con el análisis utilizando BeautifulSoup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    data = []\n",
    "    print(url)\n",
    "\n",
    "    # Encuentra todos los elementos <section> que contienen los detalles de las universidades\n",
    "    university_sections = soup.find_all('section', class_='wrapper-semestre')\n",
    "\n",
    "    for section in university_sections:\n",
    "        # Extrae el ciclo desde el div con la clase 'btn-semestre'\n",
    "        ciclo = section.find('div', class_='btn-semestre').text.strip()\n",
    "\n",
    "        career_title_div = soup.find('div', id='career-title')\n",
    "\n",
    "        if career_title_div:\n",
    "            # Extrae el nombre de la carrera desde el elemento <h2>\n",
    "            carrera = career_title_div.find('h2').text.strip()\n",
    "            facultad = career_title_div.find('p').text.strip()\n",
    "        else:\n",
    "            carrera = \"Carrera no encontrada\"\n",
    "            facultad = \"Facultad no encontrada\"\n",
    "\n",
    "        # Extrae el nombre de la universidad desde el elemento <p>\n",
    "        universidad_elem = soup.find('p')\n",
    "        if universidad_elem:\n",
    "            universidad = universidad_elem.text.strip()\n",
    "        else:\n",
    "            universidad = \"Universidad no encontrada\"\n",
    "\n",
    "        # Extrae los nombres de las materias desde los elementos <li> dentro del div con la clase 'link1 whitebg'\n",
    "        materias_div = section.find('div', class_='link1 whitebg')\n",
    "        materias = [li.text.strip() for li in materias_div.find_all('li')]\n",
    "        # Transforma las modalidades según tus requisitos\n",
    "        # Extrae las modalidades de inscripción\n",
    "        modalidades_elem = soup.find('div', class_='boton-inscripcion').find_all('a')\n",
    "        modalidades = [modalidad_elem.text.strip() for modalidad_elem in modalidades_elem]\n",
    "        # Convertir todas las modalidades a minúsculas antes de realizar los reemplazos\n",
    "        modalidades = [modalidad.lower() for modalidad in modalidades]\n",
    "        \n",
    "        # Realizar el reemplazo de la modalidad \"presencial\"\n",
    "        modalidades = [modalidad.replace(\"modalidad presencial - inscríbete a la prueba de admisión\", \"presencial\") for modalidad in modalidades]\n",
    "        \n",
    "        # Realizar el reemplazo de la modalidad \"distancia\"\n",
    "        modalidades = [modalidad.replace(\"modalidad a distancia - matricúlate ahora\", \"distancia\") for modalidad in modalidades]\n",
    "\n",
    "\n",
    "        # Extraer el título que otorga\n",
    "        titulo = soup.select(\".item:nth-child(2) div\")[0].get_text(strip=True)\n",
    "        \n",
    "            \n",
    "        # Extraer la duración\n",
    "        duracion = soup.select(\".item:nth-child(3) div\")[0].get_text(strip=True)\n",
    "\n",
    "        # Extraer la descripción de la carrera\n",
    "        descripcion_div = soup.find('div', class_='section1')\n",
    "        descripcion_items = descripcion_div.find_all(['li', 'p'], class_='rtejustify')\n",
    "        print(descripcion_items)\n",
    "        \n",
    "        if descripcion_items:\n",
    "            descripcion = ' '.join(item.text.strip() for item in descripcion_items)\n",
    "        else:\n",
    "            descripcion = \"Descripción no encontrada\"\n",
    "            \n",
    "        # Crea una fila por cada materia y ciclo para cada modalidad\n",
    "        for materia in materias:\n",
    "            for modalidad in modalidades:\n",
    "                extracted_data = {\n",
    "                    'carrera': carrera,\n",
    "                    'ciclo': ciclo,\n",
    "                    'materia': materia,\n",
    "                    'facultad': facultad,\n",
    "                    'universidad': universidad,\n",
    "                    'modalidad': modalidad,\n",
    "                    'descripcion': descripcion,\n",
    "                    'titulo': titulo.split(\":\", 1)[1].strip(),  # Extraer el texto después de \":\"\n",
    "                    'duracion': duracion.split(\":\", 1)[1].strip()  # Extraer el texto después de \":\"\n",
    "                    \n",
    "                }\n",
    "                data.append(extracted_data)\n",
    "\n",
    "    csv_file = 'datos_universidades.csv'\n",
    "    file_exists = os.path.exists(csv_file)\n",
    "\n",
    "    with open(csv_file, 'a', newline='', encoding='utf-8') as file:\n",
    "        fieldnames = ['carrera', 'ciclo', 'facultad', 'materia', 'universidad', 'modalidad', 'descripcion','titulo', 'duracion']\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames, delimiter=';')\n",
    "\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "\n",
    "        for extracted_data in data:\n",
    "            writer.writerow(extracted_data)\n",
    "    \n",
    "\n",
    "    print(\"Datos guardados en el archivo CSV:\", csv_file)\n",
    "\n",
    "\n",
    "# scrape_and_save_data('https://www.utpl.edu.ec/carreras/empresas')\n",
    "    \n",
    "# URL de inicio\n",
    "start_url = 'https://www.utpl.edu.ec'\n",
    "\n",
    "# Llamar a la función para parsear los enlaces de carreras\n",
    "carrera_links = parse_carrera_links(start_url)\n",
    "\n",
    "# Llamar a la función scrape_and_save_data(url) para cada enlace de carrera\n",
    "for carrera_link in carrera_links:\n",
    "    full_url = start_url + carrera_link if carrera_link.startswith('/') else carrera_link\n",
    "\n",
    "    scrape_and_save_data(full_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddd05b0-927a-4ff9-8ce0-e431e796b0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
